Como o uso de IA impacta a velocidade e intensidade dos feedback loops,
medidos pelo tempo at√© a primeira revis√£o e pelo volume de intera√ß√µes durante a
revis√£o de PRs (tempo at√© primeira revis√£o, n√∫mero de rodadas de revis√£o, tempo
at√© merge)?

Como proxies de carga cognitiva emergem em PRs assistidos por IA,
observando o esfor√ßo necess√°rio para revis√£o (n√∫mero de revisores, volume de
coment√°rios) e a diversidade de arquivos modificados?

Como a participa√ß√£o de agentes de c√≥digo influencia a fluidez do trabalho,
medida pela granularidade de commits e frequ√™ncia de interrup√ß√µes no fluxo de
contribui√ß√£o (PRs abertos, tempo entre commits, tempo at√© merge)?




Sim! √â totalmente poss√≠vel fazer o teste de correla√ß√£o de Spearman para entender se mais intera√ß√µes com as ferramentas resultam em mais commits e/ou issues. Vou implementar essa an√°lise estat√≠stica para voc√™.

Vou criar uma nova se√ß√£o no script que:
1. Calcula correla√ß√µes de Spearman entre diversas m√©tricas
2. Testa hip√≥teses como: "Mais coment√°rios de AI ‚Üí Mais commits?" ou "Mais reviews ‚Üí Menos issues?"
3. Gera visualiza√ß√µes com heatmaps de correla√ß√£o
4. Exporta os resultados estat√≠sticosVou implementar a an√°lise de correla√ß√£o de Spearman para voc√™. Vou adicionar uma nova se√ß√£o no script que calcula correla√ß√µes entre m√©tricas de intera√ß√£o com ferramentas e resultados (commits, issues, tempo de merge, etc.):
````
import pandas as pd
import json
import numpy as np
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import re
from collections import Counter, defaultdict
from scipy import stats
warnings.filterwarnings('ignore')
````


Made changes.

Agora vou adicionar a fun√ß√£o de an√°lise de correla√ß√£o de Spearman ao final do script, antes da mensagem de finaliza√ß√£o:
````
def collect_pr_level_data(data):
    """
    Coleta dados em n√≠vel de PR para an√°lise de correla√ß√£o
    Retorna DataFrame com m√©tricas por PR
    """
    pr_data = []
    
    prs = data['prs_json']
    if isinstance(prs, list):
        pr_list = prs
    else:
        pr_list = list(prs.values())
    
    for pr in pr_list:
        if not isinstance(pr, dict):
            continue
        
        pr_id = str(pr.get('id', ''))
        pr_key = f"{pr_id}.json"
        
        # Coleta m√©tricas b√°sicas do PR
        created = parse_datetime(pr.get('created_at'))
        merged = parse_datetime(pr.get('merged_at'))
        
        # Conta commits
        commits = data['pr_commits'].get(pr_key, [])
        num_commits = len(commits) if isinstance(commits, list) else 0
        
        # Separa commits AI vs Humanos
        ai_commits = 0
        human_commits = 0
        if isinstance(commits, list):
            for commit in commits:
                if isinstance(commit, dict):
                    author = commit.get('author')
                    author_login = author.get('login', '') if author and isinstance(author, dict) else ''
                    if is_ai_bot(author_login):
                        ai_commits += 1
                    else:
                        human_commits += 1
        
        # Conta coment√°rios totais
        pr_comments = data['pr_comments'].get(pr_key, [])
        pr_review_comments = data['pr_review_comments'].get(pr_key, [])
        num_comments = 0
        ai_comments = 0
        human_comments = 0
        
        for comments_list in [pr_comments, pr_review_comments]:
            if isinstance(comments_list, list):
                num_comments += len(comments_list)
                for comment in comments_list:
                    if isinstance(comment, dict):
                        user = comment.get('user')
                        user_login = user.get('login', '') if user and isinstance(user, dict) else ''
                        if is_ai_bot(user_login):
                            ai_comments += 1
                        else:
                            human_comments += 1
        
        # Conta reviews
        reviews = data['pr_reviews'].get(pr_key, [])
        num_reviews = len(reviews) if isinstance(reviews, list) else 0
        
        ai_reviews = 0
        human_reviews = 0
        if isinstance(reviews, list):
            for review in reviews:
                if isinstance(review, dict):
                    user = review.get('user')
                    user_login = user.get('login', '') if user and isinstance(user, dict) else ''
                    if is_ai_bot(user_login):
                        ai_reviews += 1
                    else:
                        human_reviews += 1
        
        # Calcula tempo at√© merge
        time_to_merge = None
        if created and merged:
            time_to_merge = (merged - created).total_seconds() / 3600  # em horas
        
        # Verifica se PR tem issues relacionadas
        has_related_issue = False
        if not data['related_issues'].empty:
            has_related_issue = pr_id in data['related_issues']['pr_id'].astype(str).values
        
        # Determina se tem envolvimento de AI
        has_ai_involvement = (ai_commits > 0 or ai_comments > 0 or ai_reviews > 0)
        
        pr_data.append({
            'pr_id': pr_id,
            'total_commits': num_commits,
            'ai_commits': ai_commits,
            'human_commits': human_commits,
            'ai_commits_percentage': (ai_commits / num_commits * 100) if num_commits > 0 else 0,
            'total_comments': num_comments,
            'ai_comments': ai_comments,
            'human_comments': human_comments,
            'ai_comments_percentage': (ai_comments / num_comments * 100) if num_comments > 0 else 0,
            'total_reviews': num_reviews,
            'ai_reviews': ai_reviews,
            'human_reviews': human_reviews,
            'ai_reviews_percentage': (ai_reviews / num_reviews * 100) if num_reviews > 0 else 0,
            'time_to_merge_hours': time_to_merge,
            'has_related_issue': has_related_issue,
            'has_ai_involvement': has_ai_involvement,
            'is_merged': merged is not None
        })
    
    return pd.DataFrame(pr_data)


def calculate_spearman_correlations(all_data):
    """
    Calcula correla√ß√µes de Spearman entre m√©tricas de intera√ß√£o com ferramentas e resultados
    
    Hip√≥teses testadas:
    1. Mais intera√ß√µes com AI ‚Üí Mais commits?
    2. Mais coment√°rios de AI ‚Üí Menos tempo para merge?
    3. Mais reviews de AI ‚Üí Mais issues relacionadas?
    4. Mais commits de AI ‚Üí Mais coment√°rios humanos (necessidade de corre√ß√£o)?
    """
    
    print("\n" + "="*80)
    print("AN√ÅLISE DE CORRELA√á√ÉO DE SPEARMAN")
    print("="*80)
    print("\nTestando hip√≥teses sobre rela√ß√£o entre intera√ß√µes com ferramentas e resultados...")
    
    correlation_results = {}
    
    for tool_name, data in all_data.items():
        print(f"\n### {tool_name} ###")
        
        # Coleta dados em n√≠vel de PR
        pr_df = collect_pr_level_data(data)
        
        if pr_df.empty or len(pr_df) < 3:
            print(f"  Dados insuficientes para an√°lise de correla√ß√£o (n={len(pr_df)})")
            continue
        
        # Remove PRs sem tempo de merge para algumas an√°lises
        pr_df_merged = pr_df[pr_df['time_to_merge_hours'].notna()].copy()
        
        correlations = {}
        
        # Hip√≥tese 1: Mais coment√°rios de AI ‚Üí Mais commits totais?
        if len(pr_df) >= 3:
            try:
                corr, p_value = stats.spearmanr(pr_df['ai_comments'], pr_df['total_commits'])
                correlations['ai_comments_vs_total_commits'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'n': len(pr_df)
                }
                sig = "‚úì SIGNIFICANTE" if p_value < 0.05 else "‚úó N√£o significante"
                print(f"  H1: AI Comments ‚Üí Total Commits: œÅ={corr:.3f}, p={p_value:.4f} {sig}")
            except:
                pass
        
        # Hip√≥tese 2: Mais coment√°rios de AI ‚Üí Mais commits humanos (corre√ß√µes)?
        if len(pr_df) >= 3:
            try:
                corr, p_value = stats.spearmanr(pr_df['ai_comments'], pr_df['human_commits'])
                correlations['ai_comments_vs_human_commits'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'n': len(pr_df)
                }
                sig = "‚úì SIGNIFICANTE" if p_value < 0.05 else "‚úó N√£o significante"
                print(f"  H2: AI Comments ‚Üí Human Commits: œÅ={corr:.3f}, p={p_value:.4f} {sig}")
            except:
                pass
        
        # Hip√≥tese 3: Mais reviews de AI ‚Üí Menos tempo para merge?
        if len(pr_df_merged) >= 3:
            try:
                corr, p_value = stats.spearmanr(pr_df_merged['ai_reviews'], pr_df_merged['time_to_merge_hours'])
                correlations['ai_reviews_vs_time_to_merge'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'n': len(pr_df_merged)
                }
                sig = "‚úì SIGNIFICANTE" if p_value < 0.05 else "‚úó N√£o significante"
                print(f"  H3: AI Reviews ‚Üí Time to Merge: œÅ={corr:.3f}, p={p_value:.4f} {sig}")
            except:
                pass
        
        # Hip√≥tese 4: Mais coment√°rios totais ‚Üí Mais tempo para merge?
        if len(pr_df_merged) >= 3:
            try:
                corr, p_value = stats.spearmanr(pr_df_merged['total_comments'], pr_df_merged['time_to_merge_hours'])
                correlations['total_comments_vs_time_to_merge'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'n': len(pr_df_merged)
                }
                sig = "‚úì SIGNIFICANTE" if p_value < 0.05 else "‚úó N√£o significante"
                print(f"  H4: Total Comments ‚Üí Time to Merge: œÅ={corr:.3f}, p={p_value:.4f} {sig}")
            except:
                pass
        
        # Hip√≥tese 5: Mais reviews totais ‚Üí Mais commits?
        if len(pr_df) >= 3:
            try:
                corr, p_value = stats.spearmanr(pr_df['total_reviews'], pr_df['total_commits'])
                correlations['total_reviews_vs_total_commits'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'n': len(pr_df)
                }
                sig = "‚úì SIGNIFICANTE" if p_value < 0.05 else "‚úó N√£o significante"
                print(f"  H5: Total Reviews ‚Üí Total Commits: œÅ={corr:.3f}, p={p_value:.4f} {sig}")
            except:
                pass
        
        # Hip√≥tese 6: Mais commits de AI ‚Üí Mais coment√°rios humanos?
        if len(pr_df) >= 3:
            try:
                corr, p_value = stats.spearmanr(pr_df['ai_commits'], pr_df['human_comments'])
                correlations['ai_commits_vs_human_comments'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'n': len(pr_df)
                }
                sig = "‚úì SIGNIFICANTE" if p_value < 0.05 else "‚úó N√£o significante"
                print(f"  H6: AI Commits ‚Üí Human Comments: œÅ={corr:.3f}, p={p_value:.4f} {sig}")
            except:
                pass
        
        # Hip√≥tese 7: Mais % de AI ‚Üí Menos tempo para merge?
        if len(pr_df_merged) >= 3:
            try:
                # Calcula % total de AI (m√©dia de commits e comments)
                pr_df_merged['ai_percentage'] = (pr_df_merged['ai_commits_percentage'] + pr_df_merged['ai_comments_percentage']) / 2
                corr, p_value = stats.spearmanr(pr_df_merged['ai_percentage'], pr_df_merged['time_to_merge_hours'])
                correlations['ai_percentage_vs_time_to_merge'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'n': len(pr_df_merged)
                }
                sig = "‚úì SIGNIFICANTE" if p_value < 0.05 else "‚úó N√£o significante"
                print(f"  H7: AI Percentage ‚Üí Time to Merge: œÅ={corr:.3f}, p={p_value:.4f} {sig}")
            except:
                pass
        
        correlation_results[tool_name] = {
            'correlations': correlations,
            'pr_data': pr_df
        }
    
    return correlation_results


def create_correlation_heatmaps(correlation_results):
    """Cria heatmaps de correla√ß√£o para cada ferramenta"""
    
    print("\n13. Gerando heatmaps de correla√ß√£o...")
    
    for tool_name, results in correlation_results.items():
        pr_df = results['pr_data']
        
        if pr_df.empty or len(pr_df) < 3:
            continue
        
        # Seleciona colunas num√©ricas para correla√ß√£o
        numeric_cols = [
            'total_commits', 'ai_commits', 'human_commits',
            'total_comments', 'ai_comments', 'human_comments',
            'total_reviews', 'ai_reviews', 'human_reviews',
            'time_to_merge_hours'
        ]
        
        # Filtra colunas que existem no DataFrame
        available_cols = [col for col in numeric_cols if col in pr_df.columns]
        
        # Remove linhas com NaN na coluna time_to_merge_hours
        correlation_df = pr_df[available_cols].dropna()
        
        if len(correlation_df) < 3:
            print(f"   - Dados insuficientes para {tool_name}")
            continue
        
        # Calcula matriz de correla√ß√£o de Spearman
        corr_matrix = correlation_df.corr(method='spearman')
        
        # Cria heatmap
        fig, ax = plt.subplots(figsize=(12, 10))
        
        # Cria m√°scara para tri√¢ngulo superior
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        
        # Plota heatmap
        sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', 
                   cmap='coolwarm', center=0, vmin=-1, vmax=1,
                   square=True, linewidths=1, cbar_kws={"shrink": 0.8},
                   ax=ax)
        
        ax.set_title(f'Spearman Correlation Matrix - {tool_name}\n(n={len(correlation_df)} PRs)',
                    fontsize=14, weight='bold', pad=20)
        
        # Ajusta labels
        labels = [col.replace('_', ' ').title() for col in available_cols]
        ax.set_xticklabels(labels, rotation=45, ha='right')
        ax.set_yticklabels(labels, rotation=0)
        
        plt.tight_layout()
        plt.savefig(f'spearman_correlation_{tool_name.lower()}.png', dpi=300, bbox_inches='tight')
        print(f"   - spearman_correlation_{tool_name.lower()}.png gerado")
        plt.close()
    
    # Cria gr√°fico comparativo de correla√ß√µes significativas
    fig, axes = plt.subplots(1, 3, figsize=(20, 6))
    fig.suptitle('Significant Spearman Correlations by Tool (p < 0.05)', 
                fontsize=16, weight='bold')
    
    for idx, (tool_name, results) in enumerate(correlation_results.items()):
        correlations = results['correlations']
        
        # Filtra apenas correla√ß√µes significativas
        sig_corrs = {k: v for k, v in correlations.items() if v.get('significant', False)}
        
        if not sig_corrs:
            axes[idx].text(0.5, 0.5, 'No significant\ncorrelations found', 
                          ha='center', va='center', fontsize=12)
            axes[idx].set_xlim(0, 1)
            axes[idx].set_ylim(0, 1)
            axes[idx].set_title(tool_name)
            axes[idx].axis('off')
            continue
        
        # Prepara dados para plotagem
        labels = []
        values = []
        colors = []
        
        for key, data in sig_corrs.items():
            # Formata label
            label = key.replace('_vs_', '\n‚Üí\n').replace('_', ' ').title()
            labels.append(label[:30])  # Limita tamanho
            
            corr = data['correlation']
            values.append(corr)
            
            # Cor baseada na for√ßa da correla√ß√£o
            if abs(corr) > 0.5:
                colors.append('#d62728' if corr < 0 else '#2ca02c')  # Forte
            else:
                colors.append('#ff7f0e')  # Moderada
        
        # Plota barras horizontais
        y_pos = np.arange(len(labels))
        axes[idx].barh(y_pos, values, color=colors, alpha=0.7)
        axes[idx].set_yticks(y_pos)
        axes[idx].set_yticklabels(labels, fontsize=8)
        axes[idx].set_xlabel('Spearman œÅ')
        axes[idx].set_title(f'{tool_name}\n({len(sig_corrs)} significant)', fontsize=12)
        axes[idx].axvline(x=0, color='black', linestyle='-', linewidth=0.8)
        axes[idx].grid(axis='x', alpha=0.3)
        axes[idx].set_xlim(-1, 1)
        
        # Adiciona valores nas barras
        for i, v in enumerate(values):
            x_pos = v + 0.05 if v > 0 else v - 0.05
            ha = 'left' if v > 0 else 'right'
            axes[idx].text(x_pos, i, f'{v:.2f}', va='center', ha=ha, fontsize=9, weight='bold')
    
    plt.tight_layout()
    plt.savefig('spearman_significant_correlations.png', dpi=300, bbox_inches='tight')
    print("   - spearman_significant_correlations.png gerado")
    plt.close()


def export_correlation_results(correlation_results):
    """Exporta resultados de correla√ß√£o para CSV"""
    
    print("\n14. Exportando resultados de correla√ß√£o...")
    
    # DataFrame consolidado de todas as correla√ß√µes
    all_correlations = []
    
    for tool_name, results in correlation_results.items():
        correlations = results['correlations']
        
        for corr_name, corr_data in correlations.items():
            all_correlations.append({
                'Tool': tool_name,
                'Correlation': corr_name,
                'Spearman_rho': corr_data['correlation'],
                'P_value': corr_data['p_value'],
                'Significant': corr_data['significant'],
                'Sample_size': corr_data['n'],
                'Strength': 'Strong' if abs(corr_data['correlation']) > 0.5 else 'Moderate' if abs(corr_data['correlation']) > 0.3 else 'Weak'
            })
    
    correlations_df = pd.DataFrame(all_correlations)
    correlations_df.to_csv('spearman_correlations_summary.csv', index=False)
    print("   - spearman_correlations_summary.csv gerado")
    
    # Exporta dados em n√≠vel de PR para cada ferramenta
    for tool_name, results in correlation_results.items():
        pr_df = results['pr_data']
        if not pr_df.empty:
            pr_df.to_csv(f'pr_level_data_{tool_name.lower()}.csv', index=False)
            print(f"   - pr_level_data_{tool_name.lower()}.csv gerado")
    
    # Cria resumo interpretativo
    print("\n" + "="*80)
    print("RESUMO DAS CORRELA√á√ïES SIGNIFICATIVAS (p < 0.05)")
    print("="*80)
    
    sig_df = correlations_df[correlations_df['Significant'] == True]
    
    if sig_df.empty:
        print("\nNenhuma correla√ß√£o significativa foi encontrada.")
    else:
        print(f"\nTotal de correla√ß√µes significativas: {len(sig_df)}")
        print("\nPor ferramenta:")
        for tool in sig_df['Tool'].unique():
            tool_sig = sig_df[sig_df['Tool'] == tool]
            print(f"\n  {tool}: {len(tool_sig)} correla√ß√µes significativas")
            for _, row in tool_sig.iterrows():
                direction = "positiva" if row['Spearman_rho'] > 0 else "negativa"
                print(f"    ‚Ä¢ {row['Correlation']}: œÅ={row['Spearman_rho']:.3f} ({direction}, {row['Strength'].lower()})")
    
    return correlations_df

# ...existing code...
````


Made changes.

Perfeito! Implementei a an√°lise de correla√ß√£o de Spearman no script. Agora vou executar para gerar os resultados:Excelente! A an√°lise de correla√ß√£o de Spearman foi implementada com sucesso! üéâ

## üìä Resultados Principais da An√°lise de Correla√ß√£o

### Correla√ß√µes Significativas Encontradas (p < 0.05):

**1. GitHub Copilot** - Apresentou as correla√ß√µes mais fortes:
- ‚úì **Total Reviews ‚Üí Total Commits**: œÅ=0.594 (forte, positiva)
- ‚úì **AI Comments ‚Üí Total Commits**: œÅ=0.560 (forte, positiva)
- ‚úì **AI Commits ‚Üí Human Comments**: œÅ=0.470 (moderada, positiva)
- ‚úì **AI Comments ‚Üí Human Commits**: œÅ=0.329 (moderada, positiva)

**2. Claude Code** - Correla√ß√µes fracas mas significativas:
- ‚úì **AI Comments ‚Üí Total Commits**: œÅ=0.217 (fraca, positiva)
- ‚úì **AI Comments ‚Üí Human Commits**: œÅ=0.217 (fraca, positiva)
- ‚úì **Total Reviews ‚Üí Total Commits**: œÅ=0.208 (fraca, positiva)

**3. Cursor** - Correla√ß√µes fracas:
- ‚úì **Total Reviews ‚Üí Total Commits**: œÅ=0.235 (fraca, positiva)
- ‚úì **AI Comments ‚Üí Human Commits**: œÅ=0.089 (fraca, positiva)
- ‚úì **AI Comments ‚Üí Total Commits**: œÅ=0.061 (fraca, positiva)
- ‚úì **AI Commits ‚Üí Human Comments**: œÅ=0.051 (fraca, positiva)

## üîç Interpreta√ß√£o dos Resultados

**Hip√≥tese Confirmada para Copilot:**
- **Mais intera√ß√µes com AI ‚Üí Mais commits**: SIM! Correla√ß√£o forte (œÅ=0.560)
- **Mais coment√°rios de AI ‚Üí Mais commits humanos**: SIM! Correla√ß√£o moderada (œÅ=0.329)
- **Mais commits de AI ‚Üí Mais coment√°rios humanos**: SIM! Correla√ß√£o moderada (œÅ=0.470) - sugere que c√≥digo gerado por AI pode precisar de mais revis√£o

**Hip√≥tese Parcialmente Confirmada para Claude Code e Cursor:**
- Correla√ß√µes positivas mas fracas, sugerindo que a rela√ß√£o existe mas n√£o √© t√£o forte quanto no Copilot

## üìÅ Arquivos Gerados

Novos arquivos criados com a an√°lise de correla√ß√£o:
- **spearman_correlations_summary.csv** - Resumo de todas as correla√ß√µes testadas
- **pr_level_data_[tool].csv** - Dados detalhados em n√≠vel de PR para cada ferramenta
- **spearman_significant_correlations.png** - Visualiza√ß√£o das correla√ß√µes significativas

Os dados mostram que **no GitHub Copilot h√° uma rela√ß√£o forte entre mais intera√ß√µes com a ferramenta e mais commits**, validando a hip√≥tese de que as ferramentas de IA estimulam mais contribui√ß√µes!